{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import transforms, utils, datasets, models\n",
    "from torch.nn.modules.loss import BCEWithLogitsLoss\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from time import time\n",
    "\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data.dataloader import DataLoader, default_collate\n",
    "import wandb\n",
    "\n",
    "from augraphy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_path = '/data/ephemeral/home/data/meta.csv'\n",
    "train_path = '/data/ephemeral/home/data/train.csv'\n",
    "submission_path = '/data/ephemeral/home/data/sample_submission.csv'\n",
    "\n",
    "meta_data = pd.read_csv(meta_path)\n",
    "df_train = pd.read_csv(train_path)\n",
    "df_submission = pd.read_csv(submission_path)\n",
    "\n",
    "merge = pd.merge(df_train, meta_data, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시드를 고정합니다.\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv, path, album_transform=None, augraphy_transform=None):\n",
    "        self.df = pd.read_csv(csv).values\n",
    "        self.path = path \n",
    "        self.album_transform = album_transform\n",
    "        self.augraphy_transform = augraphy_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img_path = os.path.join(self.path, name)\n",
    "        \n",
    "        try:\n",
    "            img = Image.open(img_path)\n",
    "            img = np.array(img)\n",
    "            \n",
    "            if self.augraphy_transform:\n",
    "                img = self.augraphy_transform(img)\n",
    "\n",
    "            if self.album_transform:\n",
    "                img = self.album_transform(image=img)['image']\n",
    "            \n",
    "            return img, target\n",
    "        except (IOError, OSError):\n",
    "            print(f\"Cannot read image: {img_path}\")\n",
    "            return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timm.data.mixup import Mixup\n",
    "from timm.loss import SoftTargetCrossEntropy\n",
    "import torch.nn as nn\n",
    "\n",
    "# 여기서 Mixup을 위한 설정을 추가합니다.\n",
    "mixup_fn = Mixup(\n",
    "    mixup_alpha=0.3, cutmix_alpha=0.0, prob=0.8, switch_prob=0.5, mode='elem',\n",
    "    label_smoothing=0.1, num_classes=17\n",
    ")\n",
    "\n",
    "# Mixup 사용 시 SoftTargetCrossEntropy 사용, 아니면 기본 CrossEntropyLoss 사용\n",
    "criterion = SoftTargetCrossEntropy() if mixup_fn is not None else nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset, ConcatDataset\n",
    "import random\n",
    "\n",
    "oversampling_factors = [1.0] * 17\n",
    "oversampling_factors[1] = 2.0  # (100/50)\n",
    "oversampling_factors[13] = 1.35  # (100/74)\n",
    "oversampling_factors[14] = 2.0  # (100/50)\n",
    "\n",
    "def oversample_subset_per_class(dataset, oversampling_factors):\n",
    "    oversampled_datasets = []\n",
    "    class_to_indices = {}\n",
    "    for i in range(len(dataset)):\n",
    "        _, label = dataset[i]\n",
    "        if label not in class_to_indices:\n",
    "            class_to_indices[label] = []\n",
    "        class_to_indices[label].append(i)\n",
    "\n",
    "    for label, indices in class_to_indices.items():\n",
    "        oversampling_factor = oversampling_factors[label]\n",
    "        oversampled_indices = random.choices(indices, k=int(len(indices) * oversampling_factor) // 2 * 2)\n",
    "        oversampled_subset = Subset(dataset, oversampled_indices)\n",
    "        oversampled_datasets.append(oversampled_subset)\n",
    "    \n",
    "    oversampled_dataset = ConcatDataset(oversampled_datasets)\n",
    "    print(f\"Oversampled | {len(dataset)} -> {len(oversampled_dataset)}\")\n",
    "    return oversampled_dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def training(model, dataloader, device, criterion, optimizer, epoch, num_epochs, mixup_fn=None):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    tbar = tqdm(dataloader)\n",
    "    for batch in tbar:\n",
    "        images, labels = batch\n",
    "        \n",
    "        # None 값 확인 및 건너뛰기\n",
    "        if images is None or labels is None:\n",
    "            continue  # 손상된 파일을 만나면 이 배치를 건너뛰고 다음으로 진행\n",
    "        \n",
    "        images = images.type(torch.cuda.FloatTensor)\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        if mixup_fn is not None:\n",
    "            images, labels = mixup_fn(images, labels)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        if mixup_fn is None:\n",
    "            preds_list.extend(outputs.argmax(dim=1).detach().cpu().numpy())\n",
    "            targets_list.extend(labels.detach().cpu().numpy())\n",
    "\n",
    "        tbar.set_description(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss : {loss.item():.4f}\")\n",
    "\n",
    "    train_loss = train_loss / len(dataloader)\n",
    "    train_acc = None\n",
    "    train_f1 = None\n",
    "\n",
    "    if mixup_fn is None:\n",
    "        train_acc = accuracy_score(targets_list, preds_list) if len(targets_list) > 0 else 0\n",
    "        train_f1 = f1_score(targets_list, preds_list, average='macro') if len(targets_list) > 0 else 0\n",
    "\n",
    "    metrics = {\n",
    "        'train_loss': train_loss,\n",
    "        'train_acc': train_acc,\n",
    "        'train_f1': train_f1\n",
    "    }\n",
    "\n",
    "    return model, metrics\n",
    "\n",
    "\n",
    "\n",
    "def evaluation(model, dataloader, dataset, device, criterion, epoch, num_epochs):\n",
    "    model.eval()\n",
    "    valid_loss = 0.0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "    batch_count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        tbar = tqdm(dataloader)\n",
    "        for batch in tbar:\n",
    "            images, labels = batch\n",
    "            \n",
    "            # None 값 확인 및 건너뛰기\n",
    "            if images is None or labels is None:\n",
    "                continue  # 손상된 파일을 만나면 이 배치를 건너뛰고 다음으로 진행\n",
    "            \n",
    "            images = images.type(torch.cuda.FloatTensor)\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            valid_loss += loss.item()\n",
    "            batch_count += 1  # 배치 개수를 카운트합니다.\n",
    "\n",
    "            preds_list.extend(outputs.argmax(dim=1).detach().cpu().numpy())\n",
    "            targets_list.extend(labels.detach().cpu().numpy())\n",
    "\n",
    "            tbar.set_description(f\"Epoch [{epoch+1}/{num_epochs}] Valid Loss : {valid_loss/batch_count:.4f}\")\n",
    "\n",
    "    if batch_count > 0:  # 배치가 처리된 경우에만 계산\n",
    "        valid_loss /= batch_count  # 배치 개수로 나누어 평균 손실을 계산합니다.\n",
    "        valid_acc = accuracy_score(preds_list, targets_list)\n",
    "        valid_f1 = f1_score(preds_list, targets_list, average='macro')\n",
    "    else:  # 처리된 배치가 없는 경우(모든 배치가 건너뛰어진 경우)\n",
    "        valid_loss = None\n",
    "        valid_acc = None\n",
    "        valid_f1 = None\n",
    "\n",
    "    metrics = {\n",
    "        'valid_loss': valid_loss,\n",
    "        'valid_acc': valid_acc,\n",
    "        'valid_f1': valid_f1\n",
    "    }\n",
    "\n",
    "    return model, metrics\n",
    "\n",
    "def training_loop(model, train_dataloader, valid_dataloader, train_dataset, valid_dataset, criterion, optimizer, device, num_epochs, model_path, model_name, patience, run,scheduler):\n",
    "\n",
    "    best_valid_loss = float('inf')\n",
    "    valid_max_accuracy = -1\n",
    "    valid_max_f1 = -1\n",
    "    early_stop_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model, train_metrics = training(model, train_dataloader, device, criterion, optimizer, epoch, num_epochs, mixup_fn)\n",
    "        model, valid_metrics = evaluation(model, valid_dataloader, valid_dataset, device, criterion, epoch, num_epochs)\n",
    "        scheduler.step()\n",
    "\n",
    "        monitoring_value = {\n",
    "            'train_loss': train_metrics['train_loss'],\n",
    "            'valid_loss': valid_metrics['valid_loss']\n",
    "        }\n",
    "        run.log(monitoring_value, step=epoch)\n",
    "\n",
    "        # 검증 손실을 기준으로 최고 성능 모델 저장 및 조기 종료 판단\n",
    "        if valid_metrics['valid_loss'] < best_valid_loss:\n",
    "            best_valid_loss = valid_metrics['valid_loss']\n",
    "            early_stop_counter = 0  # 카운터 초기화\n",
    "            # 모델 저장\n",
    "            torch.save(model.state_dict(), f\"{model_path}/model_{model_name}.pt\")\n",
    "            # WandB 요약 정보 업데이트\n",
    "            run.summary['best_train_loss'] = train_metrics['train_loss']\n",
    "            run.summary['best_valid_loss'] = valid_metrics['valid_loss']\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "            \n",
    "        \n",
    "        if early_stop_counter >= patience:\n",
    "            print('Early Stopping!')        \n",
    "            break\n",
    "\n",
    "    return model, valid_max_accuracy, valid_max_f1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_csv_path = '/data/ephemeral/home/filtered_final.csv'\n",
    "df_img = pd.read_csv(img_csv_path)\n",
    "print(df_img.head())\n",
    "len(df_img)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations.core.transforms_interface import ImageOnlyTransform\n",
    "\n",
    "\n",
    "class NonLocalMeansDenoising(ImageOnlyTransform):\n",
    "    def __init__(self, h=10, templateWindowSize=7, searchWindowSize=21, always_apply=False, p=0.5):\n",
    "        super(NonLocalMeansDenoising, self).__init__(always_apply, p)\n",
    "        self.h = h\n",
    "        self.templateWindowSize = templateWindowSize\n",
    "        self.searchWindowSize = searchWindowSize\n",
    "\n",
    "    def apply(self, image, **params):\n",
    "        # OpenCV는 BGR 형태로 이미지를 처리하므로, RGB 이미지를 BGR로 변환\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        # Non-Local Means Denoising 적용\n",
    "        denoised_image = cv2.fastNlMeansDenoisingColored(image, None, self.h, self.h, self.templateWindowSize, self.searchWindowSize)\n",
    "        # 결과 이미지를 다시 RGB로 변환\n",
    "        denoised_image = cv2.cvtColor(denoised_image, cv2.COLOR_BGR2RGB)\n",
    "        return denoised_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '/data/ephemeral/home/lmj2' \n",
    "test_img_path = '/data/ephemeral/home/data/test/'\n",
    "totensor_transform = A.Compose([A.Resize(380, 380), ToTensorV2()])\n",
    "test_transform = A.Compose([\n",
    "    A.Resize(380, 380),\n",
    "    ToTensorV2()\n",
    "])\n",
    "# 이미지 변환 설정\n",
    "totensor_transform = A.Compose([A.Resize(380, 380), ToTensorV2()])\n",
    "test_transform = A.Compose([\n",
    "    A.Resize(380, 380),\n",
    "    #NonLocalMeansDenoising(h=10, templateWindowSize=7, searchWindowSize=21, p=1.0), # Non-Local Means 적용, p=1.0은 항상 적용\n",
    "    #A.GaussianBlur(blur_limit=(3, 7), p=0.5),  # 가우시안 블러 적용, p는 적용 확률\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# 데이터셋 로드\n",
    "train_dataset = ImageDataset(img_csv_path, img_path, album_transform=totensor_transform, augraphy_transform=None)\n",
    "test_dataset = ImageDataset(submission_path, test_img_path, album_transform=test_transform, augraphy_transform=None)\n",
    "\n",
    "# 데이터셋 크기 출력\n",
    "print(f\"Original train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "\n",
    "# 훈련 데이터와 검증 데이터로 분리 (random_split 사용)\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "valid_size = len(train_dataset) - train_size\n",
    "train_dataset, valid_dataset = torch.utils.data.random_split(train_dataset, [train_size, valid_size])\n",
    "\n",
    "# def custom_collate_fn(batch):\n",
    "#     # 배치에서 None 항목을 제외\n",
    "#     batch = [item for item in batch if item[0] is not None and item[1] is not None]\n",
    "#     # 배치 크기가 홀수인 경우 마지막 항목 제거\n",
    "#     if len(batch) % 2 != 0:\n",
    "#         batch = batch[:-1]\n",
    "#     # 배치가 완전히 비었을 경우, DataLoader가 처리할 수 있는 유효한 빈 배치 반환\n",
    "#     if len(batch) == 0:\n",
    "#         return torch.tensor([]), torch.tensor([])\n",
    "#     return default_collate(batch)\n",
    "\n",
    "\n",
    "# 데이터로더 생성\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)#, collate_fn=custom_collate_fn)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=32, shuffle=False)#, collate_fn=custom_collate_fn)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 데이터셋 크기 및 데이터로더 준비 상태 출력\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Valid dataset size: {len(valid_dataset)}\")\n",
    "print(f\"Train dataloader size: {len(train_dataloader)}\")\n",
    "print(f\"Valid dataloader size: {len(valid_dataloader)}\")\n",
    "print(f\"Test dataloader size: {len(test_dataloader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 오버샘플링용\n",
    "\n",
    "# img_path = 'data/aug_dataset/aug_2'\n",
    "# test_img_path = '/data/ephemeral/home/data/test/'\n",
    "# totensor_transform = A.Compose([A.Resize(380, 380), ToTensorV2()])\n",
    "# test_transform = A.Compose([\n",
    "#     A.Resize(380, 380),\n",
    "#     ToTensorV2()\n",
    "# ])\n",
    "\n",
    "# # 데이터셋 로드\n",
    "# train_dataset = ImageDataset(img_csv_path, img_path, album_transform=totensor_transform, augraphy_transform=None)\n",
    "# test_dataset = ImageDataset(submission_path, test_img_path, album_transform=test_transform, augraphy_transform=None)\n",
    "\n",
    "# # 오버샘플링 적용 전 데이터셋 크기 출력\n",
    "# print(f\"Original train dataset size: {len(train_dataset)}\")\n",
    "# print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "\n",
    "# # 훈련 데이터와 검증 데이터로 분리 (random_split 사용)\n",
    "# train_size = int(0.8 * len(train_dataset))\n",
    "# valid_size = len(train_dataset) - train_size\n",
    "# train_dataset, valid_dataset = torch.utils.data.random_split(train_dataset, [train_size, valid_size])\n",
    "\n",
    "# # 오버샘플링 적용 (가정: oversample_subset_per_class 함수가 정의되어 있음)\n",
    "# oversampled_train_dataset = oversample_subset_per_class(train_dataset, oversampling_factors)\n",
    "\n",
    "# # 데이터로더 생성\n",
    "# train_dataloader = DataLoader(oversampled_train_dataset, batch_size=32, shuffle=True)\n",
    "# valid_dataloader = DataLoader(valid_dataset, batch_size=32, shuffle=False)\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# # 오버샘플링 적용 후 데이터셋 크기 및 데이터로더 준비 상태 출력\n",
    "# print(f\"Oversampled train dataset size: {len(oversampled_train_dataset)}\")\n",
    "# print(f\"Valid dataset size: {len(valid_dataset)}\")\n",
    "# print(f\"Train dataloader size: {len(train_dataloader)}\")\n",
    "# print(f\"Valid dataloader size: {len(valid_dataloader)}\")\n",
    "# print(f\"Test dataloader size: {len(test_dataloader)}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Original train dataset size: 23550\n",
    "# # Test dataset size: 3140\n",
    "# # Oversampled | 18840 -> 20300\n",
    "# # Oversampled train dataset size: 20300\n",
    "# # Valid dataset size: 4710\n",
    "# # Train dataloader size: 635\n",
    "# # Valid dataloader size: 148\n",
    "# # Test dataloader size: 99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model('efficientnet_b4', pretrained=True)\n",
    "in_features = model.classifier.in_features\n",
    "classifier = nn.Sequential(\n",
    "    nn.Linear(in_features, 1024),\n",
    "    nn.BatchNorm1d(1024),\n",
    "    nn.SiLU(),\n",
    "    nn.Dropout(p=0.2),\n",
    "    nn.Linear(1024, 512),\n",
    "    nn.BatchNorm1d(512),\n",
    "    nn.SiLU(),\n",
    "    nn.Dropout(p=0.2),\n",
    "    nn.Linear(512, 256),\n",
    "    nn.BatchNorm1d(256),\n",
    "    nn.SiLU(),\n",
    "    nn.Dropout(p=0.2),\n",
    "    nn.Linear(256, 17),\n",
    ") \n",
    " \n",
    "model.classifier = classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper Parameter 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cfg():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    num_epochs = 100\n",
    "    batch_size=32\n",
    "    model_path = '/data/ephemeral/home/models'\n",
    "\n",
    "    scheduler = StepLR(optimizer, step_size=5, gamma=0.5)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #run = wandb.init(project='AIStage-CV', name='effb4_add_fc')\n",
    "\n",
    "# device = Cfg.device\n",
    "# model = Cfg.model\n",
    "# criterion = Cfg.criterion\n",
    "# optimizer = Cfg.optimizer \n",
    "# num_epochs = Cfg.num_epochs\n",
    "# model_name = 'effb4-add_fc'\n",
    "# model_path = Cfg.model_path\n",
    "\n",
    "# #run.watch(model, criterion, log='all', log_graph=True)\n",
    "\n",
    "# #model, valid_max_accuracy, valid_max_f1 = training_loop(model, train_dataloader, valid_dataloader, train_dataset, valid_dataset, criterion, optimizer, device, num_epochs, model_path, model_name, 10, run, Cfg.scheduler)\n",
    "\n",
    "# #run.finish()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# import os\n",
    "\n",
    "# def check_corrupted_images(dataset_directory_path):\n",
    "#     image_extensions = ['.jpg', '.jpeg', '.png', '.bmp']  # 이미지 확장자 리스트\n",
    "#     corrupted_count = 0\n",
    "#     total_count = 0\n",
    "\n",
    "#     # 데이터셋 디렉토리 내의 모든 파일 순회\n",
    "#     for root, dirs, files in os.walk(dataset_directory_path):\n",
    "#         for file in files:\n",
    "#             if any(file.lower().endswith(ext) for ext in image_extensions):\n",
    "#                 total_count += 1\n",
    "#                 file_path = os.path.join(root, file)\n",
    "#                 try:\n",
    "#                     with Image.open(file_path) as img:\n",
    "#                         img.verify()  # 이미지 파일 검증\n",
    "#                 except (IOError, SyntaxError) as e:\n",
    "#                     print(f\"손상된 파일 발견: {file_path}\")\n",
    "#                     corrupted_count += 1\n",
    "\n",
    "#     return total_count, corrupted_count\n",
    "\n",
    "# # 데이터셋 디렉토리 경로 설정\n",
    "# dataset_directory_path = '/data/ephemeral/home/lmj'\n",
    "# total_images, corrupted_images = check_corrupted_images(dataset_directory_path)\n",
    "\n",
    "# print(f\"전체 이미지 수: {total_images}, 손상된 이미지 수: {corrupted_images}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run = wandb.init(project='AIStage-CV', name='effb4_add_fc')\n",
    "\n",
    "device = Cfg.device\n",
    "model = Cfg.model\n",
    "criterion = Cfg.criterion\n",
    "optimizer = Cfg.optimizer \n",
    "num_epochs = Cfg.num_epochs\n",
    "model_name = 'effb4-add_fc' \n",
    "model_path = Cfg.model_path\n",
    "\n",
    "#run.watch(model, criterion, log='all', log_graph=True)\n",
    "\n",
    "#model, valid_max_accuracy, valid_max_f1 = training_loop(model, train_dataloader, valid_dataloader, train_dataset, valid_dataset, criterion, optimizer, device, num_epochs, model_path, model_name, 10, run, Cfg.scheduler)\n",
    "\n",
    "#run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 경로\n",
    "csv_path = '/data/ephemeral/home/real_final.csv'\n",
    "# 이미지가 저장된 폴더 경로\n",
    "img_folder_path = '/data/ephemeral/home/data/aug_dataset/aug_2'\n",
    "\n",
    "# CSV 파일 로드\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# 이미지 파일명이 있는 컬럼 이름, 예를 들어 'image_name'이라고 가정\n",
    "image_column_name = 'ID'  # 실제 컬럼 이름으로 변경해야 함\n",
    "\n",
    "# 누락된 파일 검사\n",
    "missing_files = []\n",
    "for image_name in df[image_column_name]:\n",
    "    image_path = os.path.join(img_folder_path, image_name)\n",
    "    if not os.path.exists(image_path):\n",
    "        missing_files.append(image_name)\n",
    "\n",
    "# 누락된 파일 출력\n",
    "for missing_file in missing_files:\n",
    "    print(missing_file)\n",
    "\n",
    "# 누락된 파일의 개수 출력\n",
    "print(f\"Total missing files: {len(missing_files)}\")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "effb4 = timm.create_model('efficientnet_b4', pretrained=True)\n",
    "in_features = effb4.classifier.in_features\n",
    "classifier = nn.Sequential(\n",
    "    nn.Linear(in_features, 1024),\n",
    "    nn.BatchNorm1d(1024),\n",
    "    nn.SiLU(), # relu -> swish 변경 \n",
    "    nn.Dropout(p=0.2),\n",
    "    nn.Linear(1024, 512),\n",
    "    nn.BatchNorm1d(512),\n",
    "    nn.SiLU(),\n",
    "    nn.Dropout(p=0.2),\n",
    "    nn.Linear(512, 256),\n",
    "    nn.BatchNorm1d(256),\n",
    "    nn.SiLU(),\n",
    "    nn.Dropout(p=0.2),\n",
    "    nn.Linear(256, 17),\n",
    ")\n",
    "\n",
    "effb4.classifier = classifier\n",
    "effb4.load_state_dict(torch.load('/data/ephemeral/home/models/model_effb4-add_fc.pt'))\n",
    "effb4 = effb4.to(device)\n",
    "effb4.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original\n",
    "\n",
    "preds_list = []\n",
    "\n",
    "for images, labels in tqdm(test_dataloader):\n",
    "    images = images.type(torch.cuda.FloatTensor)\n",
    "    images = images.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        preds = effb4(images)\n",
    "    preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from torchvision import transforms\n",
    "# from tqdm import tqdm\n",
    "# from torch.nn import functional as F\n",
    "\n",
    "# # 모델 평가 모드 설정\n",
    "# model.eval()\n",
    "\n",
    "# # TTA 변환 목록\n",
    "# transformation_list = [\n",
    "#     transforms.Compose([transforms.RandomHorizontalFlip(p=1)]),\n",
    "#     transforms.Compose([transforms.RandomVerticalFlip(p=1)]),\n",
    "#     transforms.Compose([transforms.RandomRotation(degrees=90)]),\n",
    "#     transforms.Compose([transforms.RandomRotation(degrees=179)])\n",
    "# ]\n",
    "\n",
    "# # 결과 저장을 위한 딕셔너리\n",
    "# preds_dict = {}\n",
    "# probs_dict = {}\n",
    "\n",
    "# # TTA가 적용된 이미지 수를 저장할 변수\n",
    "# tta_applied_count = 0\n",
    "\n",
    "# # test_dataloader의 각 배치에 대해 반복\n",
    "# for batch_idx, (images, _) in enumerate(tqdm(test_dataloader)):\n",
    "#     images = images.float().to(device)  # 이미지를 device로 이동 및 데이터 타입 변경\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         outputs = effb4(images)\n",
    "#         probs = torch.softmax(outputs, dim=1)\n",
    "#         max_probs, preds = torch.max(probs, dim=1)\n",
    "        \n",
    "#         # 각 이미지에 대하여\n",
    "#         for i in range(images.size(0)):\n",
    "#             img_index = batch_idx * test_dataloader.batch_size + i  # 이미지의 전역 인덱스 계산\n",
    "#             if max_probs[i] >= 0.50:\n",
    "#                 # 확률이 0.5 이상인 경우, 직접 결과 딕셔너리에 추가\n",
    "#                 preds_dict[img_index] = preds[i].item()\n",
    "#                 probs_dict[img_index] = max_probs[i].item()\n",
    "#             else:\n",
    "#                 # 확률이 0.5 미만인 경우, TTA 적용을 위해 별도 처리\n",
    "#                 tta_probs = []\n",
    "#                 for transformation in transformation_list:\n",
    "#                     # 변환 적용\n",
    "#                     transformed_image = transformation(images[i].unsqueeze(0)).to(device)\n",
    "                    \n",
    "#                     with torch.no_grad():\n",
    "#                         tta_output = model(transformed_image)\n",
    "#                         tta_prob = torch.softmax(tta_output, dim=1)\n",
    "#                         tta_probs.append(tta_prob)\n",
    "                \n",
    "#                 # TTA 결과의 평균 확률 계산\n",
    "#                 avg_tta_probs = torch.mean(torch.stack(tta_probs), dim=0)\n",
    "#                 avg_max_prob, avg_pred = torch.max(avg_tta_probs, dim=1)\n",
    "                \n",
    "#                 # 평균 확률을 기반으로 최종 예측 결정\n",
    "#                 preds_dict[img_index] = avg_pred.item()\n",
    "#                 probs_dict[img_index] = avg_max_prob.item()  # TTA로 계산된 평균 확률 사용\n",
    "#                 tta_applied_count += 1\n",
    "\n",
    "# # 결과를 인덱스에 따라 정렬하여 최종 리스트 생성\n",
    "# sorted_indices = sorted(preds_dict.keys())\n",
    "# final_preds = [preds_dict[i] for i in sorted_indices]\n",
    "# final_probs = [probs_dict[i] for i in sorted_indices]\n",
    "\n",
    "# print(f\"Number of predictions with TTA applied: {tta_applied_count}\")\n",
    "# print(f\"Total predictions: {len(final_preds)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(test_dataset.df, columns=['ID', 'target'])\n",
    "pred_df['target'] = preds_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission_df = pd.read_csv(submission_path)\n",
    "assert (sample_submission_df['ID'] == pred_df['ID']).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.to_csv('/data/ephemeral/home/outputs/effb4-add_fc.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df\n",
    "\n",
    "# ID\ttarget\n",
    "# 0\t0008fdb22ddce0ce.jpg\t[4]\n",
    "# 1\t00091bffdffd83de.jpg\t[3]\n",
    "# 2\t00396fbc1f6cc21d.jpg\t[3]\n",
    "# 3\t00471f8038d9c4b6.jpg\t[3]\n",
    "# 4\t00901f504008d884.jpg\t[4]\n",
    "\n",
    "## 0.9434\n",
    "\n",
    "# \tID\ttarget\n",
    "# 0\t0008fdb22ddce0ce.jpg\t2\n",
    "# 1\t00091bffdffd83de.jpg\t12\n",
    "# 2\t00396fbc1f6cc21d.jpg\t5\n",
    "# 3\t00471f8038d9c4b6.jpg\t12\n",
    "# 4\t00901f504008d884.jpg\t2\n",
    "# ...\t...\t...\n",
    "# 3135\tffb4b6f619fb60ea.jpg\t6\n",
    "# 3136\tffb54299b1ad4159.jpg\t10\n",
    "# 3137\tffc2c91dff8cf2c0.jpg\t8\n",
    "# 3138\tffc4e330a5353a2a.jpg\t0\n",
    "# 3139\tffc71fed753d90c1.jpg\t12\n",
    "\n",
    "## 이상\n",
    "\n",
    "# ID\ttarget\n",
    "# 0\t0008fdb22ddce0ce.jpg\t4\n",
    "# 1\t00091bffdffd83de.jpg\t3\n",
    "# 2\t00396fbc1f6cc21d.jpg\t3\n",
    "# 3\t00471f8038d9c4b6.jpg\t3\n",
    "# 4\t00901f504008d884.jpg\t4\n",
    "# ...\t...\t...\n",
    "# 3135\tffb4b6f619fb60ea.jpg\t3\n",
    "# 3136\tffb54299b1ad4159.jpg\t3\n",
    "# 3137\tffc2c91dff8cf2c0.jpg\t3\n",
    "# 3138\tffc4e330a5353a2a.jpg\t4\n",
    "# 3139\tffc71fed753d90c1.jpg\t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_distribution = pred_df['target'].value_counts()\n",
    "\n",
    "print(target_distribution)\n",
    "\n",
    "## 0.9434\n",
    "\n",
    "# target\n",
    "# 7     225\n",
    "# 6     204\n",
    "# 10    203\n",
    "# 8     200\n",
    "# 9     200\n",
    "# 2     200\n",
    "# 0     200\n",
    "# 15    200\n",
    "# 5     200\n",
    "# 16    200\n",
    "# 12    197\n",
    "# 11    195\n",
    "# 4     184\n",
    "# 3     180\n",
    "# 13    156\n",
    "# 14    107\n",
    "# 1      89\n",
    "# Name: count, dtype: int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 읽기\n",
    "df1 = pd.read_csv(\"/data/ephemeral/home/1.csv\")\n",
    "df2 = pd.read_csv(\"/data/ephemeral/home/2.csv\")\n",
    "df3 = pd.read_csv(\"/data/ephemeral/home/data/sample_submission.csv\")\n",
    "\n",
    "# 인덱스를 기준으로 ID 값이 모두 같은 항목의 개수 계산\n",
    "matching_count = 0\n",
    "\n",
    "# 세 데이터프레임의 길이가 다를 수 있으므로, 가장 작은 길이를 기준으로 반복\n",
    "min_length = min(len(df1), len(df2), len(df3))\n",
    "\n",
    "for i in range(min_length):\n",
    "    if df1.loc[i, \"ID\"] == df2.loc[i, \"ID\"] == df3.loc[i, \"ID\"]:\n",
    "        matching_count += 1\n",
    "\n",
    "print(f\"인덱스에 따른 ID값이 모두 같은 항목의 개수: {matching_count}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
